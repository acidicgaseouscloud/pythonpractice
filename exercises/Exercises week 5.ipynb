{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises week 5\n",
    "\n",
    "In these exercises, you will work with a set of 19th century novels from Project Gutenberg, specifically the 18 texts in the directory `data/gutenberg/training/` (which was part of the chapter 4 notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, encoding='utf8') as infile:\n",
    "        contents = infile.read()\n",
    "    return contents\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preProcess(text):\n",
    "    return [token.lower() for token in nltk.word_tokenize(text) if token not in '''!()-[]{};:'\"\\,<>./?@#$%^&*_~''']'melania & michelle', 'melania & laura', 'michelle & laura'\n",
    "\n",
    "def tokenize_sent(sent):\n",
    "    return [token.lower() for token in nltk.word_tokenize(sent)\n",
    "           if token not in \".,?!:;()[]''``*\"]\n",
    "\n",
    "def preprocess(text):\n",
    "    return [tokenize_sent(sent) for sent in nltk.sent_tokenize(text)]\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from os.path import splitext, basename\n",
    "\n",
    "corpus = {}\n",
    "\n",
    "for filepath in glob('data/gutenberg/training/*.txt'):\n",
    "    text = read_file(filepath)\n",
    "    corpus[splitext(basename(filepath))[0]] = preprocess(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability in 19th century fiction\n",
    "\n",
    "Read the corpus, split it into sentences, and tokenize and clean it in the same way as in notebook chapter 4.\n",
    "It is useful to put the result into a dictionary `corpus`, with filenames as keys, and the tokenized/sentence-splitted texts as values.\n",
    "\n",
    "Implement a function `readability(text)`. It should use the ARI formula (see the slides from week 1) to estimate the readability of a tokenized text.\n",
    "\n",
    "Apply this function to each novel, and store the results in a dictionary mapping filenames to readability scores.\n",
    "Look at the results:\n",
    "\n",
    "- Who is the most difficult to read?\n",
    "- Do you see interesting or surprising results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blake-poems 7.3330006097189155\n",
      "whitman-poems 11.37180744901056\n",
      "carroll-alice 5.890725046288502\n",
      "shakespeare-caesar 4.258179826361175\n",
      "whitman-leaves 15.565010325629153\n",
      "milton-paradise 21.61959530472408\n",
      "melville-piazza 11.838610293672211\n",
      "blake-songs 8.439722163525623\n",
      "austen-pride 9.550872361895102\n",
      "whitman-patriotic 16.911261560073363\n",
      "edgeworth-parents 6.3573986007179215\n",
      "chesterton-thursday 6.8577625416159265\n",
      "burgess-busterbrown 5.340729526600175\n",
      "chesterton-ball 7.802034866703821\n",
      "austen-emma 9.454080590744201\n",
      "shakespeare-hamlet 4.231908935047343\n",
      "austen-sense 11.669015186802994\n",
      "bryant-stories 5.900936749832574\n"
     ]
    }
   ],
   "source": [
    "# your code her\n",
    "def readability(text): \n",
    "    total_sentences = len(text)\n",
    "    total_words = 0\n",
    "    total_characters = 0\n",
    "    for sentence in text: \n",
    "        total_words += len(sentence)\n",
    "        for word in sentence: \n",
    "            total_characters += len(word)           \n",
    "    words_per_sent = total_words / total_sentences \n",
    "    chars_per_word = total_characters / total_words\n",
    "    gradeLevel = 0.5 * words_per_sent + 4.71 * chars_per_word - 21.43\n",
    "    return gradeLevel\n",
    "    \n",
    "for text in corpus: \n",
    "    print(text,readability(corpus[text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {'austen-emma.txt': 9.454080590744201,\n",
    " 'bryant-stories.txt': 5.900936749832574,\n",
    " 'whitman-poems.txt': 11.37235359928885,\n",
    " 'chesterton-thursday.txt': 6.8577625416159265,\n",
    " 'burgess-busterbrown.txt': 5.340729526600175,\n",
    " 'milton-paradise.txt': 21.61922616435404,\n",
    " 'blake-poems.txt': 7.3330006097189155,\n",
    " 'blake-songs.txt': 8.439722163525623,\n",
    " 'edgeworth-parents.txt': 6.356779166270105,\n",
    " 'shakespeare-caesar.txt': 4.258179826361175,\n",
    " 'whitman-leaves.txt': 15.565010325629153,\n",
    " 'shakespeare-hamlet.txt': 4.231908935047343,\n",
    " 'whitman-patriotic.txt': 16.911261560073363,\n",
    " 'austen-pride.txt': 9.550872361895102,\n",
    " 'carroll-alice.txt': 5.890725046288502,\n",
    " 'chesterton-ball.txt': 7.799681127108684,\n",
    " 'melville-piazza.txt': 11.838489721191259,\n",
    " 'austen-sense.txt': 11.668964287000264}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shakespeare and Milton are the easiest and hardest texts respectively. This might be because Shakespear wrote plays for the general public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment and sensibility\n",
    "\n",
    "Compute a sentiment score for each of the books, using the code on this week's slides. Create a function `sentiment(filename, positive_words, negative_words)` which returns a score for a give filename and sets of sentiment words.\n",
    "\n",
    "- The link on my slides has sentiment lexicons for 81 languages, but not English ... Use the sentiment lexicon made available at: https://github.com/BijoySingh/east/tree/master/east/datasets/opinion_lexicon\n",
    "  Click on the files and press the \"raw\" button to download the file; put them in the `data/` directory.\n",
    "- Note that for this application, we don't care about sentences, so it is easier to read the text as one big list of tokens.\n",
    "- The books have different lengths, is this a problem? If so, can you think of something to correct for this?\n",
    "- Do you see interesting/surprising patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blake-poems 66\n",
      "whitman-poems 669\n",
      "carroll-alice -76\n",
      "shakespeare-caesar 88\n",
      "whitman-leaves 835\n",
      "milton-paradise 102\n",
      "melville-piazza -718\n",
      "blake-songs 56\n",
      "austen-pride 1364\n",
      "whitman-patriotic 170\n",
      "edgeworth-parents 1424\n",
      "chesterton-thursday -643\n",
      "burgess-busterbrown 58\n",
      "chesterton-ball -621\n",
      "austen-emma 2255\n",
      "shakespeare-hamlet -30\n",
      "austen-sense 1214\n",
      "bryant-stories 443\n"
     ]
    }
   ],
   "source": [
    "# Just the sentiment\n",
    "\n",
    "def sentiment(filename, positive_words, negative_words):\n",
    "    posWords = read_file(positive_words).splitlines()\n",
    "    negWords = read_file(negative_words).splitlines()\n",
    "    sentiment = 0\n",
    "    for sentence in filename:\n",
    "        for word in sentence:\n",
    "            if word in posWords:\n",
    "                sentiment += 1\n",
    "            elif word in negWords:\n",
    "                sentiment -= 1\n",
    "    return sentiment\n",
    "\n",
    "for text in corpus:\n",
    "    print(text, sentiment(corpus[text], \"data/wordList/positive-words.txt\", \"data/wordList/negative-words.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blake-poems 0.009523809523809525\n",
      "whitman-poems 0.009696776437847866\n",
      "carroll-alice -0.0027716994894237783\n",
      "shakespeare-caesar 0.0042395336512983575\n",
      "whitman-leaves 0.0066238299222592415\n",
      "milton-paradise 0.001271091393963562\n",
      "melville-piazza -0.008892521859750811\n",
      "blake-songs 0.0096005486027773\n",
      "austen-pride 0.011091775497259584\n",
      "whitman-patriotic 0.006250919252831299\n",
      "edgeworth-parents 0.00833982441858422\n",
      "chesterton-thursday -0.010964276579418536\n",
      "burgess-busterbrown 0.0035624347398808425\n",
      "chesterton-ball -0.007495654692931634\n",
      "austen-emma 0.013702958745282962\n",
      "shakespeare-hamlet -0.000997307270370001\n",
      "austen-sense 0.009984537947823799\n",
      "bryant-stories 0.009510927905878312\n"
     ]
    }
   ],
   "source": [
    "# Accounting for number of total words\n",
    "\n",
    "def sentiment(filename, positive_words, negative_words):\n",
    "    posWords = read_file(positive_words).splitlines()\n",
    "    negWords = read_file(negative_words).splitlines()\n",
    "    sentiment = 0\n",
    "    numWords = 0 \n",
    "    for sentence in filename:\n",
    "        for word in sentence:\n",
    "            numWords += 1\n",
    "            if word in posWords:\n",
    "                sentiment += 1\n",
    "            elif word in negWords:\n",
    "                sentiment -= 1\n",
    "    return (sentiment/numWords)\n",
    "\n",
    "for text in corpus:\n",
    "    print(text, sentiment(corpus[text], \"data/wordList/positive-words.txt\", \"data/wordList/negative-words.txt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some books have a negative value, whereas others have a positive value. By dividing by total number of words we can get the proportion of the sentiment. \n",
    "\n",
    "For example, Jane austen has a value reaching 0.1 and thus has the most positive sentiment exhibited in the corpus. Chesterton has the most negative value at -0.01."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
